# Qualität eines LLMs durch LoRA verbessern

## Was ist LoRA?

Low-Rank Adaptation of Large Language Models
- Anpassung von Basismodellen durch kleine, leichte Erännzungen
- ohne eigenes Modell zu erstellen oder ein bestehendes weiter zu trainieren

## Wie funktioniert es?

- LoRA-Adapter ermöglicht Fusion mit initialen LLM
- Referanz im Prompting auf gegebene Inhalte?

## Vor- und Nachteile im Eisnatz von LoRA

## Beispiele

- LoRA in Stable Diffusion: https://anakin.ai/de/blog/how-to-use-lora-stable-diffusion-de/ 
- angepasste LoRAs anschauen und nutzen: 

## Hinweis/Disclaimer auf Inhalte



Quellen: https://www.mind-verse.de/en/news/effiziente-modellanpassung-kuenstliche-intelligenz-maschinelles-lernen-lora-technik-fortschritte#:~:text=LoRA%2C%20kurz%20f%C3%BCr%20%22Low-Rank%20Adaptation%20of%20Large%20Language,trainiert%20werden%2C%20erm%C3%B6glicht%20LoRA%20schnellere%20und%20speichereffizientere%20Trainingsprozesse.

